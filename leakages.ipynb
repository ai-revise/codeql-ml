{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VjBW2TVkDQGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example for Test Leakage Error - balancing"
      ],
      "metadata": {
        "id": "-1FZS_WmDQdO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBlK4WFa6yVy",
        "outputId": "9d3c6a10-35f1-4551-efb5-7dde2f500bfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Balanced Accuracy (balancing before split - With leakage): 0.9425772429366085\n",
            "Balanced Accuracy (balancing after split - No leakage): 0.5099789915966386\n"
          ]
        }
      ],
      "source": [
        "import sklearn\n",
        "from sklearn.datasets import make_classification\n",
        "import numpy as np\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "\n",
        "# Generate random and very unbalanced data\n",
        "X, y = make_classification(n_samples=1000, weights=[0.9], random_state=42)\n",
        "np.random.default_rng(seed=42).shuffle(y)\n",
        "\n",
        "\n",
        "# Apply balancing before train-test split\n",
        "sm = SMOTE(random_state=42)\n",
        "X_res, y_res = sm.fit_resample(X, y)\n",
        "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X_res, y_res, test_size=0.3, random_state=42)\n",
        "clf = sklearn.ensemble.RandomForestClassifier(random_state=42).fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\"Balanced Accuracy (balancing before split - With leakage):\", sklearn.metrics.balanced_accuracy_score(y_test, y_pred))\n",
        "\n",
        "# Correct approach: Apply balancing after train-test split\n",
        "X_train_orig, X_test_orig, y_train_orig, y_test_orig = sklearn.model_selection.train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_train_res, y_train_res = sm.fit_resample(X_train_orig, y_train_orig)\n",
        "clf_correct = sklearn.ensemble.RandomForestClassifier(random_state=42).fit(X_train_res, y_train_res)\n",
        "y_pred_correct = clf_correct.predict(X_test_orig)\n",
        "print(\"Balanced Accuracy (balancing after split - No leakage):\", sklearn.metrics.balanced_accuracy_score(y_test_orig, y_pred_correct))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "from sklearn.datasets import make_classification\n",
        "import numpy as np\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "\n",
        "# Generate random and very unbalanced data\n",
        "X, y = make_classification(n_samples=1000, weights=[0.9], random_state=42)\n",
        "np.random.default_rng(seed=42).shuffle(y)\n",
        "\n",
        "\n",
        "# Apply balancing before train-test split\n",
        "sm = SMOTE(random_state=42)\n",
        "X_res, y_res = sm.fit_resample(X, y)\n",
        "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X_res, y_res, test_size=0.3, random_state=42)\n",
        "clf = sklearn.ensemble.RandomForestClassifier(random_state=42).fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\"Balanced Accuracy (With leakage):\", sklearn.metrics.balanced_accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQ6aOc029ALv",
        "outputId": "8f137787-f28c-4f70-80c2-94e881fdd70b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Balanced Accuracy (With leakage): 0.9425772429366085\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EiT8G83IGoBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example for Test Leakage Error - features"
      ],
      "metadata": {
        "id": "sjHI5HkiGqtY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "Xnum = 10000\n",
        "np.random.seed(42)\n",
        "\n",
        "X = np.random.rand(500, Xnum)\n",
        "\n",
        "# Create balanced binary labels\n",
        "y = np.array([0, 1] * 250)\n",
        "\n",
        "# Shuffle the labels to make them completely random\n",
        "np.random.shuffle(y)\n",
        "\n",
        "# Apply feature selection before train-test split (Incorrect approach)\n",
        "selector = SelectKBest(f_classif, k=10)\n",
        "X_selected = selector.fit_transform(X, y)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.3, random_state=42)\n",
        "clf = RandomForestClassifier(random_state=42).fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\"Balanced Accuracy (feature selection before split - With leakage):\", balanced_accuracy_score(y_test, y_pred))\n",
        "\n",
        "# Correct approach: Apply feature selection after train-test split\n",
        "X_train_orig, X_test_orig, y_train_orig, y_test_orig = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "selector_correct = SelectKBest(f_classif, k=10)\n",
        "X_train_res = selector_correct.fit_transform(X_train_orig, y_train_orig)\n",
        "X_test_res = selector_correct.transform(X_test_orig)\n",
        "clf_correct = RandomForestClassifier(random_state=42).fit(X_train_res, y_train_orig)\n",
        "y_pred_correct = clf_correct.predict(X_test_res)\n",
        "print(\"Balanced Accuracy (feature selection after split - No leakage):\", balanced_accuracy_score(y_test_orig, y_pred_correct))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Hx8PrPbGv4M",
        "outputId": "6be9f2d2-3e78-47e3-8ca1-55b9f5417084"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Balanced Accuracy (feature selection before split - With leakage): 0.6232142857142857\n",
            "Balanced Accuracy (feature selection after split - No leakage): 0.4633928571428571\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example for Validation Leakage Error - balancing"
      ],
      "metadata": {
        "id": "qcQXJtMlDbXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split, PredefinedSplit\n",
        "from sklearn.metrics import  balanced_accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "N = 2000\n",
        "\n",
        "# Generate a dataset with 2 informative features and 500 random features\n",
        "X, y = make_classification(n_samples=N, n_features=2, n_informative=2, n_redundant=0, n_repeated=0, n_classes=2, n_clusters_per_class=1, weights=[0.95], flip_y=0, random_state=42)\n",
        "random_features = np.random.rand(N, 500)\n",
        "X = np.hstack((X, random_features))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Improper SMOTE before validation split\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
        "X_train_res, X_val_res, y_train_res, y_val_res = train_test_split(X_train_smote, y_train_smote, test_size=0.3, random_state=42)\n",
        "train_val_fold = np.concatenate([np.full(len(X_train_res), -1), np.zeros(len(X_val_res))])\n",
        "X_combined = np.vstack((X_train_res, X_val_res))\n",
        "y_combined = np.hstack((y_train_res, y_val_res))\n",
        "ps = PredefinedSplit(test_fold=train_val_fold)\n",
        "pipeline_improper = Pipeline([\n",
        "    ('select_k_best', SelectKBest(f_classif)),\n",
        "    ('rf', RandomForestClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "param_grid_improper = {\n",
        "    'select_k_best__k': [1, 2, 5, 10, 20, 50, 100]\n",
        "}\n",
        "\n",
        "grid_search_improper = GridSearchCV(pipeline_improper, param_grid_improper, cv=ps, scoring='roc_auc', verbose=1)\n",
        "grid_search_improper.fit(X_combined, y_combined)\n",
        "\n",
        "best_params_improper = grid_search_improper.best_params_\n",
        "best_score_improper = grid_search_improper.best_score_\n",
        "\n",
        "print(f\"Best params found (Improper): {best_params_improper} with validation AUC: {best_score_improper}\")\n",
        "\n",
        "pipeline_improper.set_params(**best_params_improper)\n",
        "pipeline_improper.fit(X_train_res, y_train_res)\n",
        "\n",
        "y_pred_improper = pipeline_improper.predict_proba(X_test)[:, 1]\n",
        "print(\"Balanced Accuracy (SMOTE before validation split):\", balanced_accuracy_score(y_test, pipeline_improper.predict(X_test)))\n",
        "\n",
        "# Correct approach: Apply SMOTE after splitting validation set\n",
        "X_train_orig, X_val_orig, y_train_orig, y_val_orig = train_test_split(X_train, y_train, test_size=0.3, random_state=42)\n",
        "\n",
        "X_train_smote_correct, y_train_smote_correct = smote.fit_resample(X_train_orig, y_train_orig)\n",
        "\n",
        "X_combined_correct = np.vstack((X_train_smote_correct, X_val_orig))\n",
        "y_combined_correct = np.hstack((y_train_smote_correct, y_val_orig))\n",
        "train_val_fold_correct = np.concatenate([np.full(len(X_train_smote_correct), -1), np.zeros(len(X_val_orig))])\n",
        "ps_correct = PredefinedSplit(test_fold=train_val_fold_correct)\n",
        "\n",
        "pipeline_correct = Pipeline([\n",
        "    ('select_k_best', SelectKBest(f_classif)),\n",
        "    ('rf', RandomForestClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "param_grid_correct = {\n",
        "    'select_k_best__k': [1, 2, 5, 10, 20, 50, 100]\n",
        "}\n",
        "\n",
        "grid_search_correct = GridSearchCV(pipeline_correct, param_grid_correct, cv=ps_correct, scoring='roc_auc', verbose=1)\n",
        "grid_search_correct.fit(X_combined_correct, y_combined_correct)\n",
        "\n",
        "best_params_correct = grid_search_correct.best_params_\n",
        "best_score_correct = grid_search_correct.best_score_\n",
        "\n",
        "print(f\"Best params found (Proper): {best_params_correct} with validation AUC: {best_score_correct}\")\n",
        "\n",
        "pipeline_correct.set_params(**best_params_correct)\n",
        "pipeline_correct.fit(X_train_smote_correct, y_train_smote_correct)\n",
        "\n",
        "y_pred_correct = pipeline_correct.predict_proba(X_test)[:, 1]\n",
        "print(\"Balanced Accuracy (SMOTE after validation split):\", balanced_accuracy_score(y_test, pipeline_correct.predict(X_test)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkYGX-K0CB3y",
        "outputId": "67b6578f-1b41-42d1-e71d-db5a0a284905"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 1 folds for each of 7 candidates, totalling 7 fits\n",
            "Best params found (Improper): {'select_k_best__k': 100} with validation AUC: 0.9996476325899316\n",
            "Balanced Accuracy (SMOTE before validation split): 0.5384323640960809\n",
            "Fitting 1 folds for each of 7 candidates, totalling 7 fits\n",
            "Best params found (Proper): {'select_k_best__k': 5} with validation AUC: 0.910126582278481\n",
            "Balanced Accuracy (SMOTE after validation split): 0.7359039190897598\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vd"
      ],
      "metadata": {
        "id": "x7tXTek96y6P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}